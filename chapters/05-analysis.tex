
\chapter{Cache evaluation analysis}

\section{Payloads}

\subsection{Zephyr based matrix-multiplication}

% TODO: is zephyr even imporant here? idk
Matrix multiplication is a fundamental operation in many scientific and engineering applications, including high-performance computing (e.g., finite element methods), machine
learning (e.g., linear algebra), and edge computing (e.g., DSP, edge-AI, cryptography), among others. This section discusses the implementation and of various cache multiplication algorithms,
taking into the account cache usage in each of them.

The algorithms have been implemented using the Zephyr RTOS as the execution platform. This particular RTOS has been chosen due to its support for a wide range of hardware boards,
its user-friendly build system (\texttt{CMake} alongside the \texttt{west} helper), its use of the C programming language, and its robust real-time capabilities.
Moreover, Zephyr is a collaborative project with the Linux Foundation and is the fastest-growing real-time operating system \cite{zephyrlotsofcommits}. It has commercial support
from major vendors in the embedded and edge computing sectors, such as Nordic Semiconductors, NXP, STMicroelectronics, Microchip, and many others \cite{aboutzephyr}. Additionally,
it is backed by major companies in the technology sector, including, among others, Google, Meta, Qualcomm and Intel \cite{zephyrmetagoogle, zephyrmembers}.

\noindent This payload will be used for testing \textit{different software configurations}, while the simulated \textit{hardware remains unchanged}.

\subsubsection*{Naive approach}
The naive approach to matrix multiplication involves three nested loops iterating over the rows and columns of the matrices. This method, is called naive, as it is simple, but not cache-friendly
due to its poor data locality.

\begin{center}
	\centering
	\includegraphics[width=0.75\textwidth]{figures/05-analysis/mm_naive.pdf}
	\captionof{figure}{Visual representation of the multiplication using the naive approach}
	\label{fig:mm_naive}
\end{center}

The naive approach involves three nested loops, iterating over the rows columns of the matrices:

\begin{center}
\centering
\begin{minipage}{\linewidth}
\begin{lstlisting}[
	style=lstC,
    caption={Naive matrix multiplication implemented in C programming language}
    ]
for (i = 0; i < SIZE; i++) {
	for (j = 0; j < SIZE; j++) {
		for (k = 0; k < SIZE; k++) {
			c[i * SIZE + j] += a[i * SIZE + k] * b[k * SIZE + j];
		}
	}
}
\end{lstlisting}
\end{minipage}
\end{center}

\noindent If the matrices are represented as a 1D array in memory, the naive approach to matrix multiplication results in poor cache performance due to suboptimal data locality.
The naive algorithm frequently jumps between distant memory locations, leading to cache misses.

\subsubsection*{Block based approach}
The block-based approach improves cache performance by dividing the matrices into smaller sub-matrices (blocks) that fit into the cache.

\begin{center}
	\centering
	\includegraphics[width=0.75\textwidth]{figures/05-analysis/mm_block.pdf}
	\captionof{figure}{Visual representation of the multiplication using the block based approach}
	\label{fig:mm_block}
\end{center}

\noindent By dividing the large matrix into smaller matrices, data locality is significantly improved, reducing the number of cache misses. This method is particularly effective for
large matrices, where the naive approach would otherwise result in frequent cache evictions. The larger blocks (A11, A12, B11, B12, etc.) are then multiplied and added together.
Selecting the optimal block size is a trade-off. The block size should be small enough to allow the data to fit into the cache but as large as possible to minimize runtime
overhead. Decreasing the block size results in increased runtime overhead because more instructions need to be executed.

\noindent The block-based algorithm has been implemented as follows:
\begin{center}
\centering
\begin{minipage}{\linewidth}
\begin{lstlisting}[
	style=lstC,
    caption={Block based matrix multiplication in C programming language}
    ]
const int B = BLOCK_SIZE;
for (i = 0; i < SIZE; i += B) {
	for (j = 0; j < SIZE; j += B) {
		for (k = 0; k < SIZE; k += B) {
			/* B x B mini matrix multiplications */
			for (i1 = i; i1 < i + B && i1 < SIZE; i1++) {
				for (j1 = j; j1 < j + B && j1 < SIZE; j1++) {
					for (k1 = k; k1 < k + B && k1 < SIZE; k1++) {
						c[i1 * SIZE + j1] += a[i1 * SIZE + k1] * b[k1 * SIZE + j1];
					}
				}
			}
		}
	}
}
\end{lstlisting}
\end{minipage}
\end{center}

\subsection{Linux kernel}
% TODO: this section is a biiit short
The Linux kernel is a core component of many devices, ranging from relatively small microcontrollers, to desktop computers and even HPC clusters.
It has been selected as a payload due to its relatively lengthy and memory-access-intensive boot process, such as during the unpacking of initramfs. This process is
characterized by a mix of sequential and random memory access patterns, providing a good benchmark for testing various cache configurations.

\noindent This payload will be used for testing \textit{different hardware configurations}, while the \textit{software remains unchanged}.

\section{Cache model verification}

To validate the model, it was tested against two independent data sources. The first validation was performed using the QEMU TCG Cache Modeling plugin as a reference, and the
second test was conducted by using a hardware device with built in hardware performance counters. The data input for the cache model implemented in this work was generated using
the Renode framework. This constrains the hardware choice to platforms that are compatible with both QEMU and Renode and are readily available for purchase on the market.

The RISC-V-based SiFive HiFive1 Rev B (\texttt{fu310} SoC with one \texttt{e31} RV32IMAC core) platform has been selected. This platform meets the necessary requirements for
compatibility with both QEMU and Renode, provides extensive documentation including cache parameters, and features built-in hardware performance counters.
The cache configuration for the \texttt{e31} core includes a 16 KiB 2-way set-associative instruction cache with a 32-byte block line size with \textit{random} eviction policy and
no data cache \cite{fe310docs}.

\subsection{Generating cache statistics}

The payload against which the verification was performed is the Zephyr RTOS-based matrix multiplication algorithm (naive approach). Due to the
platform's limited RAM size, the benchmark sample had to be limited to a matrix of size 16 by 16\footnote{Matrices of size $32^2$ resulted in a stack crash (manifesting itself in
a \textit{Load access fault} exception), while sizes $64^2$ and above resulted in a linker failure due to overflowing memory regions.}. The cache usage statistics are gathered
starting from the platform reset, and ended at the \texttt{finished()} symbol entry point, a helper function that marks the end of the matrix multiplication algorithm.

\subsubsection{Novel cache model \& Renode ExecutionTracer} % XXX: replace "novel"
In order to easily gather the cache statistics from the novel cache model, using the Renode framework as a trace generation backend, an \textbf{"Automated Renode Cache Test Executor"} % XXX: replace "novel"
toolset was prepared. Is a wrapper, written in bash, that configures, and pipelines the execution of both Renode and Cache model:


\begin{center}
\centering
\begin{minipage}{\linewidth}
\begin{lstlisting}[
    language=Bash,
    caption={Automated Renode Cache Test Executor}
    ]
#!/usr/bin/env bash

DIRECTORY=$1
PRESET=$2
TRACE_DIR="$(realpath traces)"
RESULT_DIR="$(realpath results)"
RENODE_LOG="RENODE_LOG"

for ELF_FILE in "$DIRECTORY"/*.elf; do
	if [ -f "$ELF_FILE" ]; then
		ELF_PATH="$(realpath $ELF_FILE)"
		ELF_FNAME=$(basename -- "$ELF_FILE" .elf)
		TRACE_PATH="$TRACE_DIR/$ELF_FNAME.log"
		RESULT_PATH="$RESULT_DIR/$ELF_FNAME.txt"

		echo "[$(date +%H:%M:%S)] Genrating traces using Renode for $ELF_FNAME" tee -a "$RENODE_LOG"

		RENODE_ELF="@$ELF_PATH" RENODE_TRACE="@$TRACE_PATH" renode --console --disable-gui 1>>"$RENODE_LOG" cache.resc &&
		renode_cache_mdl.py "$TRACE_PATH" presets "$PRESET" > "$RESULT_PATH"

		echo "[$(date +%H:%M:%S)] finished" | tee -a "$RENODE_LOG"
		echo "" | tee -a "$RENODE_LOG"
	fi
done
\end{lstlisting}
\end{minipage}
\end{center}

% \noindent The Renode script (\texttt{.resc}) file is uses the passed environment variables to set up the simulation.
\noindent The Renode script (\texttt{.resc}) file is designed to set up the simulation environment using the passed environment variables. It loads the platform description from
the \texttt{cache\_platform.repl} file - in this case this file had contained the \texttt{fu310} SoC platform description - and an ELF file specified by the environment variables.


\begin{center}
\centering
\begin{minipage}{\linewidth}
\begin{lstlisting}[
    caption={Renode script for Automated Renode Cache Test Executor}
    ]
set cacheSimulationExecutionCtrl
"""
from Antmicro.Renode.Peripherals.CPU import ICPU
sysbus = self.Machine.SystemBus
cpu = self.Machine.GetPeripheralsOfType(ICPU)[0]

def end_hook(cpu, addr):
    cpu.Pause()
    monitor.Parse("q")

for addr in sysbus.GetAllSymbolAddresses("finished"):
    cpu.AddHook(addr, end_hook)
"""

using sysbus
mach create
machine LoadPlatformDescription @cache_platform.repl
sysbus LoadELF `get_environ RENODE_ELF`

cpu MaximumBlockSize 1
cpu CreateExecutionTracing "tracer" `get_environ RENODE_TRACE` PCAndOpcode
tracer TrackMemoryAccesses

python $cacheSimulationExecutionCtrl
start
\end{lstlisting}
\end{minipage}
\end{center}

\noindent The script was executed with two arguments passed. The first argument sets the directory containing the payload ELF file, and the second argument set the cache preset to \texttt{fu310.e31}:
\begin{verbatim}
./automated_renode_cache_exec.sh elfs/ "fu310.e31"
\end{verbatim}

\noindent The Renode script was executed, and the resulting cache simulation data were saved to a file. These results are presented in Table \ref{table:cache_results}.


\subsubsection{QEMU TCG Cache Modeling plugin}
The QEMU was invoked with the following parameters:
\begin{verbatim}
qemu-system-riscv32 -nographic           \
	-machine sifive_e                       \ # simulate fu310 SoC
	-icount align=off,sleep=off             \ # decouple virtual and host time
	-kernel payload.elf                     \ # payload executable
	-plugin ./contrib/plugins/libcache.so,  \ # use TCG Cache modelling plugin
	        icachesize=16384,               \ # 16 KiB cache size
	        iassoc=2,                       \ # 2-way set-associativity
	        iblksize=32,                    \ # 32 bytes block size
	        evict=rand                      \ # random eviction policy
	-s -S                                     # enable GDB stub and wait for connection
\end{verbatim}

\noindent The virtual platform was then connected to using \texttt{riscv64-zephyr-elf-gdb}, a breakpoint was placed on the \texttt{finished()} symbol, and the execution was started:
\begin{verbatim}
riscv64-zephyr-elf-gdb payload.elf   \
	-ex 'target extended-remote :1234'  \ # connect to QEMU GDB stub
	-ex 'break finished'                \ # stop execution upon entering finished()
	-ex 'continue'                        # start executing the payload
\end{verbatim}

\noindent After the program halted at the breakpoint, the QEMU simulator was terminated, and the resulting cache simulation data were saved to a file. These results are presented in % TODO: too much passive voice? this reads weeeird
Table \ref{table:cache_results}.


\subsubsection{Hardware Performance Counters}
The \texttt{fu310} system-on-chip has a built-in Hardware Performance Monitor (HPM), that can be configured to measure a variety of performance statistics. These counters are configured
using the RISC-V Control and Status Registers (CSRs) \cite{fe310docs, riscvisa}. Although the Zephyr RTOS provides a set of C macros to interface with CSRs, 


\subsection{Verification results}

\begin{center}
\begin{table}[h!]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Environment} & \textbf{Accesses} & \textbf{Misses} & \textbf{Hits} & \textbf{HMR} \\ \hline
Renode generated trace + Cache model    & 91468        & 291         & a & a\\ \hline
QEMU TCG Cache Modeling Plugin          & 91470        & 292         & a & a\\ \hline
Hardware performance counters          & -        & 292         & - & -\\ \hline % TODO: XXX: NASTY: i think it might be possible to get the accesses using the minstret csr?
\end{tabular}
\caption{Instruction accesses and misses for QEMU and Renode environments}
\label{table:cache_results}
\end{table}
\end{center}

\section{Benchmarks}
\subsection{Automated matrix multiplication payload builder}
\subsection{Automated Renode test executor} \label{sec:renodetestexecutor}
\subsection{Benchmark results}
